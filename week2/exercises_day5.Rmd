---
title: "exercises_day5"
output: html_document
---

# Reproduce the table in ISRS 5.29 using the original dataset in body.dat.txt, taken from (http://jse.amstat.org/v11n2/datasets.heinz.html)

```{r}
library(tidyverse)

data <-  read.table("body.dat.txt",sep="", header=FALSE)
weights_and_heights <- data[, 23:25]
colnames(weights_and_heights) <- c("weight", "height", "gender")
weights_and_heights$gender <- as.factor(weights_and_heights$gender)

model <- lm(weight ~ height, data=weights_and_heights)
summary(model)

weights_and_heights %>%
  ggplot(aes(x= height, y = weight, color = gender)) +
  geom_point() +  
  geom_smooth(method='lm')
  
```



####################################################################



```{r}

baby_weights <-  read.table("babyweights.txt", sep="", header=TRUE)
head(baby_weights)
```

Relationship between baby weight and smoking status of mother
Based on table from the book:
   i) weight = 123.05 - 8.94 * smoke
   ii) for smoker: 123.05 - 8.94 x 1 = 114.11
      for non-smoker: 123.05 - 8.94 x 0 = 123.05
   iii) H0 = No difference in weight
       p-value < 5%. Thus, we reject null-hypothesis

```{r}
weight_smoke_model <- lm(weight~ smoke, data=baby_weights)
summary(weight_smoke_model)
```

#####################################################################
Relationship between baby weight and smoking status of mother
Based on the model above:
  i) weight = 129.63 - 2.81 * smoke
  ii) for smoker: 129.63 - 2.81*1 = 126.82
      for non-smoker: 129.63 - 2.81*1 = 129.63
  iii) H0 = No difference in weight
       p-value < 5%. Thus, we reject null-hypothesis.


#####################################################################

Relationship between baby weight and parity
Based on table from the book: 
  i) weight = 120.07 - 1.93 * parity
  ii) first-born: 120.07 - 1.93* 0 = 120.07
      otherwise: 120.07 - 1.93* 1 = 118.14
  iii) H0 = No difference in weight
       p-value > 5%. Thus, we do not reject null-hypothesis


```{r}
weight_smoke_model <- lm(weight~ parity, data=baby_weights)
summary(weight_smoke_model)
```
Average birth weight of babies based on all of the variables included in the data set:

Based on the table from the book:

i) 

weight = -80.41 + 0.44 X gestation - 3.33 X parity - 0.01 X age + 
          1.15 X height + .05 X weight - 8.40 X smoke 
          
ii)       
slope of gestation = 0.44 and slope of age = -0.01
For each unit increase in gestation, weight increases by 0.44 ounces
For each unit increase in age, weight decreases by 0.01 ounces

iii) 
Because many factors are considered at the same time, the dependencies between the variables is removed.

iv) 
Using the first row,
baby_weight_actual = 120
bany_weight_predicted = -80.41 + 0.44 X 284 - 3.33 X 0 - 0.01 X 27+ 1.15 X 62 + .05 X 100 - 8.40 X 0 = 120.58

Residual = -0.58

v) 
```{r}

var_res <- 249.28
var_weight <- 332.57
N <- 1236
niv <- 6 #(number of independent variables used)

r_squared <- 1 - var_res/var_weight
r_squared #0.2504435
adjusted_r_squared <- 1 - (var_res/var_weight) * (N - 1)/(N - niv -1)
adjusted_r_squared #0.2467842
```
####################################################################
####################################################################
####################################################################


```{r}

library(MASS)
head(Boston)
model <- lm(medv ~ lstat+age ,data=Boston )
summary(model)


model2 <- lm(medv ~ ., data = Boston)
summary(model2)

# excluding age

model3 <- lm(medv ~ .-age, data = Boston)  
summary(model3)
#OR
model3 <- update(model2 , ~.-age)
summary(model3)


# Variance Inflation Factor (1 = not correlated.
#                           Between 1 and 5 = moderately correlated.
#                           Greater than 5 = highly correlated.)
library(car)
vif(model2)


# Interaction Terms
summary(lm(medv ~ lstat*age ,data=Boston))


# Non-linear Transformations of the Predictors

model_a <- lm(medv ~ lstat , data=Boston) #linear
summary(model_a)
model_b <- lm(medv~lstat+I(lstat^2), data = Boston) # non-linear
summary(model_b)



# The anova() function performs a hypothesis test comparing the two models. The null hypothesis is that the two models fit the data equally well, and the alternative hypothesis is tha the full model is superior. 

anova(model_a , model_b)

par(mfrow=c(2,2))
plot(model_b)


#5th Order polynomial
model_5th <- lm(medv ~ poly(lstat ,5), data =Boston)
summary(model_5th)

#Log transformation
summary (lm(medv ~ log(rm),data=Boston))



```
################################################################
################################################################


# Qualitative Predictors

```{r}
library(ISLR)
attach(Carseats)
summary(Carseats)

model <- lm(Sales ~ .+Income :Advertising +Price:Age, data=Carseats)
summary(model)

#dummy variables: ShelveLocGood and  ShelveLocMedium

contrasts (ShelveLoc)
```

# Cross-Validation and the Bootstrap

```{r}
# The Validation Set Approach

library(ISLR)
attach(Auto)
set.seed(1)
train <- sample (392,196)

model <- lm(mpg ~ horsepower, data=Auto, subset=train)
mean((mpg-predict (model ,Auto))[-train ]^2)


model_quad <- lm(mpg ~ poly(horsepower, 2),data=Auto , subset=train)
mean((mpg - predict (model_quad, Auto ))[- train]^2)

model_cubed <- lm(mpg ~ poly(horsepower, 3), data=Auto, subset=train)
mean((mpg - predict(model_cubed, Auto))[-train]^2)


#using different training set
set.seed(2)
train <-sample ( 392, 196)
model <- lm(mpg ~ horsepower, data = Auto, subset = train)
mean((mpg - predict(model,  Auto))[-train]^2)

model_quad <- lm(mpg ~ poly(horsepower, 2),data=Auto , subset=train)
mean((mpg - predict (model_quad ,Auto ))[- train]^2)

model_cubed <- lm(mpg ~ poly(horsepower, 3), data=Auto, subset=train)
mean((mpg - predict(model_cubed, Auto))[-train]^2)


```


```{r}
# Leave-One-Out Cross-Validation

library(boot)

glm_model <- glm(mpg ~ horsepower ,data=Auto)
coef(glm_model)

cv_err <- cv.glm(Auto ,glm_model)
cv_err$delta


cv_error <-rep(0, 5)
for (i in 1:5){
  glm_model <-glm(mpg ~ poly(horsepower ,i),data=Auto)
  cv_error[i] <- cv.glm(Auto ,glm_model)$delta [1]
}
cv_error
```
```{r}
# k-Fold Cross-Validations

set.seed(42)
cv_error_10 <- rep(0 ,10)

for (i in 1:10){
  glm_model=glm(mpg ~ poly(horsepower ,i),data=Auto)
  cv_error_10[i]=cv.glm(Auto ,glm_model ,K=10)$delta [1]
}
cv_error_10

```



